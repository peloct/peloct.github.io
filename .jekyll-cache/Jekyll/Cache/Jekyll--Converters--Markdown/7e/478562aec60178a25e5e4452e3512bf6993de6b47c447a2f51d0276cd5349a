I"½<h2 id="q-table-ë°©ë²•ë¡ ">Q-Table ë°©ë²•ë¡ </h2>

<p>Q-Table ë°©ë²•ë¡ ì€ Environment ë¥¼ ì œí•œëœ ìƒíƒœë¡œ í‘œí˜„í•  ìˆ˜ ìˆê³  ì•¡ì…˜ ë˜í•œ í•œì •ë˜ì–´ ìˆëŠ” ê²½ìš°, action-value function ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ë¡ ì´ë‹¤.</p>

<p>Policy ëŠ” action-value function ì„ ê¸°ë°˜ìœ¼ë¡œ, í˜„ì¬ ìƒíƒœì—ì„œ argmax í•œ í–‰ë™ì„ ì„ íƒí•˜ëŠ” ê²ƒìœ¼ë¡œ í•œë‹¤. (Exploiting ì„ ìœ„í•´ ë•Œë•Œë¡œ ë‹¤ë¥¸ í–‰ë™ì„ í•˜ë„ë¡ ëœë¤ê°’ì„ ë„£ê¸°ë„ í•œë‹¤.)</p>

<p>action-value function ì€ â€œì–´ë–¤ ìƒíƒœì—, ì–´ë–¤ í–‰ë™ì„ í•˜ë©´ ìµœì¢…ì ìœ¼ë¡œ ëª‡ ì ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ”ê°€?â€ ë¥¼ ë§í•˜ê¸° ë•Œë¬¸ì—, ì´ë¥¼ ë³„ë„ì˜ í…Œì´ë¸”(Q-Table)ì— ì €ì¥í•œë‹¤ê³  í•˜ë©´ <strong>ìƒíƒœ ìˆ˜ x ì•¡ì…˜ ìˆ˜</strong> ì‚¬ì´ì¦ˆì˜ í…Œì´ë¸”ì´ ìš”êµ¬ëœë‹¤.</p>

<p>ì•„ì´ë””ì–´ëŠ” ì—¬ëŸ¬ ë²ˆì˜ ê½¤ ë§ì€ episode ë¥¼ ê±°ì¹˜ë©´ì„œ ë‹¤ìŒì˜ ì‹ìœ¼ë¡œ action-value function ì„ ê°œì„ í•˜ëŠ” ê²ƒì´ë‹¤.</p>

\[Q[ curState, action ] = R + \gamma * \max_{a \in Action} Q[ nextState, a]\]

<p>\(R\) ëŠ” ë°©ê¸ˆ action ì„ ì·¨í•¨ìœ¼ë¡œì¨ Environment ë¡œë¶€í„° ì–»ì€ reward ì´ë‹¤.</p>

<p>ë¬¸ì œëŠ” ìˆ˜ì‹ì€ Environment ê°€ deterministic í•œ ê²½ìš°ì—ë§Œ í†µí•œë‹¤. Environment ì— ë”°ë¼ì„œ ê°™ì€ ìƒíƒœì—ì„œ ì´ì „ê³¼ ê°™ì€ action ì„ ì·¨í–ˆì„ ë•Œ, ì´ì „ì˜ ê²½í—˜ê³¼ëŠ” ë‹¤ë¥¸ ìƒíƒœì— ë„ë‹¬í•˜ëŠ” Environment ë˜í•œ ìˆë‹¤.</p>

<p>ì´ëŸ¬í•œ ê²½ìš°ì— ìœ„ì˜ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ì´ ë°”ë€ë‹¤.</p>

\[Q[ curState, action ] = (1 - \alpha) * Q[ curState, action ]\]

\[+ \alpha * (R + \gamma * \max_{a \in Action} Q[ nextState, a])\]

<p>ìš”ì»¨ëŒ€ ì§€ê¸ˆì˜ ì‹¤íŒ¨ë‚˜ ì„±ê³µì„ ë°˜ë“œì‹œ ë¯¿ìœ¼ë©° ì´ì „ì˜ ê²½í—˜ì„ ë‚ ë¦¬ì§€ ì•Šê³ , ì´ì „ì˜ ê²½í—˜ì„ ì¡°ê¸ˆì”© ë‚¨ê¸°ëŠ” ê²ƒì´ë‹¤. (\(\alpha\) ëŠ” learning rate ë¼ í•˜ë©° 0ë¶€í„° 1ì‚¬ì´ì˜ ê°’ì´ë‹¤.)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">'FrozenLake-v0'</span><span class="p">)</span>
<span class="n">env</span><span class="p">.</span><span class="n">render</span><span class="p">()</span>

<span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">n</span><span class="p">,</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span><span class="p">])</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.85</span>

<span class="n">rList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">e</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">((</span><span class="n">i</span> <span class="o">//</span> <span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">new_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">=</span>\
            <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">learning_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span>\
            <span class="o">+</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="n">discount_factor</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">new_state</span><span class="p">,</span> <span class="p">:]))</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">new_state</span>
    <span class="n">rList</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">rAll</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Success rate: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">rList</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_episodes</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
</code></pre></div></div>

<p>ìœ„ëŠ” Stochastic í•œ Environment ì¸ FrozenLake ë¥¼ í‘¸ëŠ” Q-Table Method ì˜ êµ¬í˜„ì´ë‹¤.</p>
:ET