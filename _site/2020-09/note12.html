<!DOCTYPE html>
<html>



<head>
  <title>강화학습 4 (Q-Table 방법론) | JunWoo's Blog</title>
  
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="author" content="JunWoo Lee">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <link rel="stylesheet" href="/assets/css/main.css" media="all">
  <link rel="canonical" href="http://localhost:4000/2020-09/note12">
  <link rel="alternate" type="application/rss+xml" title="JunWoo&#39;s Blog"
    href="/feed.xml" />

  <!-- favicon -->
  <link rel="shortcut icon" href="/assets/img/favicon.ico" type="image/x-icon" />
  <link rel="icon" href="/assets/img/favicon.ico" type="image/x-icon" />

  <!-- font -->
  <link href="https://fonts.googleapis.com/css?family=Titillium+Web:400,400i" rel="stylesheet">
</head>

<body>
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <div class="content">

    <header class="header">

  <div class="header_content">
    <label class="theme_changer">
      <input theme_toggle type="checkbox">
      <div class="button"></div>
    </label>
    <a class="header_circle" href="/">
      <img src="/assets/img/cat.jpg" alt="catbook">
    </a>
    <span class="header_name">JunWoo Lee</span>
    <span class="header_job">programmer</span>
    <span class="header_mes"></span>

    <nav class="nav">
      
      <ul class="nav_list">
        <li class="nav_item">
          <a href="/aboutme.html">about</a>
        </li>
      </ul>
      
      
      
      <ul class="nav_list">
        <li class="nav_item">
          <a href="/categories/writing" id="aa">writing
            (1)</a>
        </li>
      </ul>
      
      
      <ul class="nav_list">
        <li class="nav_item">
          <a href="/categories/study" id="aa">study
            (13)</a>
        </li>
      </ul>
      
    </nav>
  </div>

</header>



    <nav class="mobile_menu">

  <ul class="nav_list">
    
    <li class="nav_item">
      <a href="/aboutme.html">about</a>
    </li>

    
    
    

    <li class="nav_item">
      <a href="/categories/writing" id="aa">writing (1)</a>
    </li>
    
    

    <li class="nav_item">
      <a href="/categories/study" id="aa">study (13)</a>
    </li>
    
  </ul>

</nav>
    
    <main class="main">

    <div class="post">
  <div>
    
    <p class="post_title">강화학습 4 (Q-Table 방법론)</p>
    
  </div>
  <div class="post_data">
    
    <span class="post_date">Sep 9, 2020</span>
    
    
    <span class="post_categories">
      &raquo; 
      <a href="/categories/study">study</a>
    </span>
    
  </div>
  <div class="post_content">
    <h2 id="q-table-방법론">Q-Table 방법론</h2>

<p>Q-Table 방법론은 Environment 를 제한된 상태로 표현할 수 있고 액션 또한 한정되어 있는 경우, action-value function 를 학습시키는 방법론이다.</p>

<p>Policy 는 action-value function 을 기반으로, 현재 상태에서 argmax 한 행동을 선택하는 것으로 한다. (Exploiting 을 위해 때때로 다른 행동을 하도록 랜덤값을 넣기도 한다.)</p>

<p>action-value function 은 “어떤 상태에, 어떤 행동을 하면 최종적으로 몇 점을 기대할 수 있는가?” 를 말하기 때문에, 이를 별도의 테이블(Q-Table)에 저장한다고 하면 <strong>상태 수 x 액션 수</strong> 사이즈의 테이블이 요구된다.</p>

<p>아이디어는 여러 번의 꽤 많은 episode 를 거치면서 다음의 식으로 action-value function 을 개선하는 것이다.</p>

\[Q[ curState, action ] = R + \gamma * \max_{a \in Action} Q[ nextState, a]\]

<p>\(R\) 는 방금 action 을 취함으로써 Environment 로부터 얻은 reward 이다.</p>

<p>문제는 수식은 Environment 가 deterministic 한 경우에만 통한다. Environment 에 따라서 같은 상태에서 이전과 같은 action 을 취했을 때, 이전의 경험과는 다른 상태에 도달하는 Environment 또한 있다.</p>

<p>이러한 경우에 위의 수식은 다음과 같이 바뀐다.</p>

\[Q[ curState, action ] = (1 - \alpha) * Q[ curState, action ]\]

\[+ \alpha * (R + \gamma * \max_{a \in Action} Q[ nextState, a])\]

<p>요컨대 지금의 실패나 성공을 반드시 믿으며 이전의 경험을 날리지 않고, 이전의 경험을 조금씩 남기는 것이다. (\(\alpha\) 는 learning rate 라 하며 0부터 1사이의 값이다.)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="s">'FrozenLake-v0'</span><span class="p">)</span>
<span class="n">env</span><span class="p">.</span><span class="n">render</span><span class="p">()</span>

<span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">n</span><span class="p">,</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span><span class="p">])</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.85</span>

<span class="n">rList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">e</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">((</span><span class="n">i</span> <span class="o">//</span> <span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">new_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">=</span>\
            <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">learning_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span>\
            <span class="o">+</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="n">discount_factor</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">new_state</span><span class="p">,</span> <span class="p">:]))</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">new_state</span>
    <span class="n">rList</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">rAll</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Success rate: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">rList</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_episodes</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
</code></pre></div></div>

<p>위는 Stochastic 한 Environment 인 FrozenLake 를 푸는 Q-Table Method 의 구현이다.</p>

  </div>


  
  <div class="post_comment">

    

  </div>
  

</div>

    </main>

  </div>

  <footer class="footer">
  <div>
    &copy; 2020 JunWoo Lee.
    Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a>.
    Get this theme
    <a href="https://github.com/starry99/catbook" target="_blank">here</a>.
  </div>
</footer>

  <!-- js from https://codepen.io/MrGrigri/pen/XQmWBv -->

<script>
    const themePreference = () => {
        const hasLocalStorage = localStorage.getItem('theme');
        let supports = false;
        let theme = undefined;

        if (hasLocalStorage === 'light') {
            theme = 'light';
        }
        if (hasLocalStorage === 'dark') {
            theme = 'dark';
        }

        if (window.matchMedia(`(prefers_color: dark)`).matches) {
            theme = hasLocalStorage ? hasLocalStorage : 'dark';
            supports = true;
        };
        if (window.matchMedia(`(prefers_color: light)`).matches) {
            theme = hasLocalStorage ? hasLocalStorage : 'light';
            supports = true;
        };
        if (window.matchMedia(`(prefers_color: no-preference)`).matches) {
            theme = hasLocalStorage ? hasLocalStorage : 'none';
            supports = true;
        };

        return {
            supports,
            theme
        };
    }

    document.addEventListener('DOMContentLoaded', e => {
        console.clear();

        const userThemePreference = themePreference();
        const toggle = document.querySelector('[theme_toggle]');
        const html = document.documentElement;

        const setTheme = () => {
            switch (userThemePreference.theme) {
                case 'dark':
                    toggle.checked = true;
                    html.classList.add('dark');
                    html.classList.remove('light');
                    break;
                case 'light':
                    toggle.checked = false;
                    html.classList.remove('dark');
                    html.classList.add('light');
                    break;
            }
        }
        setTheme();
        toggle.addEventListener('click', e => {
            if (toggle.checked) {
                html.classList.add('dark');
                html.classList.remove('light');
                localStorage.setItem('theme', 'dark');
            } else {
                html.classList.remove('dark');
                html.classList.add('light');
                localStorage.setItem('theme', 'light');
            }
        }, false);
    }, false);
</script>
</body>
</html>
